{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate GIANT Network (Tissue Specific Edges Only, with Hugo Annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip Tissue specific (Top Edges) network from NETwas paper \n",
    "# (http://hb.flatironinstitute.org/download)\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open('brain_top.gz', 'rb') as f_in:\n",
    "    with open('brain_top.txt', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        f_in.close()\n",
    "        f_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndex2\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41668864, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first import network table\n",
    "with open('brain_top.txt', 'r') as f:\n",
    "    nw_net = pd.read_table(f, sep = '\\t', header=None)\n",
    "f.close()\n",
    "    \n",
    "nw_net.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100008589</td>\n",
       "      <td>0.101838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1         2\n",
       "0  1  100008589  0.101838"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to make sure it imported correctly \n",
    "# nw_net.rename(columns={0:\"Node1\", 1:\"Node2\", 2:\"Post_Prob\"}, inplace=True)\n",
    "nw_net.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.genenames.org/cgi-bin/download get Entrez to Hugo mappings, create dictionary\n",
    "\n",
    "# define new dict hugo to ensembl\n",
    "h_e = {}\n",
    "\n",
    "# start adding to dict\n",
    "with open('hugo_to_entrez.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        (val,key) = line.split(\"\\t\")\n",
    "        keys = key.strip(\"\\n\")\n",
    "        h_e[keys] = val\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1BG', 'A1BG-AS1', 'A1CF', 'A2M']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(h_e.values())[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deal with a few weird cases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of key from header line \n",
    "del h_e['Entrez Gene ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZYXP1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_e['']\n",
    "# manual lookup gives gene ID 106480342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this key\n",
    "del h_e['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure ID not already in values\n",
    "106480342 in list(h_e.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually re-assign\n",
    "h_e[106480342] = 'ZYXP1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38719, 38719)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure no duplicate genes in h_e\n",
    "len(np.unique(list(h_e.values()))),len(h_e.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "# del nw_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new network for networkX object for nw_net \n",
    "with open('brain_top.txt', 'rb') as f:\n",
    "    nwnet = nx.read_edgelist(f, delimiter='\\t', data=(('post_prob',float),))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2650"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get h_e in nw_net\n",
    "not_there = []\n",
    "there = {}\n",
    "\n",
    "for n in list(nwnet.nodes()):\n",
    "    \n",
    "    # if in is a key of h_e, add to dict\n",
    "    if n in list(h_e.keys()):\n",
    "        there[n] = h_e[n]\n",
    "    \n",
    "    # if not, add to list \n",
    "    else:\n",
    "        not_there.append(n)\n",
    "\n",
    "len(not_there)\n",
    "# there are 2650 nodes not in the h_e dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100124402', '100126583', '100127889', '100127910', '100127955']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on these... \n",
    "not_there[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node attribute with fake names\n",
    "nx.set_node_attributes(nwnet, values='', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update node attribute with node names that are there\n",
    "nx.set_node_attributes(nwnet, values=there, name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100008589',\n",
       " '100009613',\n",
       " '10002',\n",
       " '100033414',\n",
       " '100037417',\n",
       " '100049587',\n",
       " '100101121',\n",
       " '100101933',\n",
       " '100124332']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that nodes now have names - list nodes \n",
    "list(nwnet.nodes())[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nw_nodelist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a7e69290782d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnw_nodelist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnw_nodelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nw_nodelist' is not defined"
     ]
    }
   ],
   "source": [
    "[n for n in nw_nodelist if nw_nodelist.count(n) >1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RNA28SN5',\n",
       " 'LINC02584',\n",
       " 'NR2E3',\n",
       " 'SNORD116-2',\n",
       " 'DDTL',\n",
       " 'SIGLEC14',\n",
       " 'TTTY23B',\n",
       " 'GNG5P4',\n",
       " 'YBX2P1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that nodes now have names - list corresponding names\n",
    "nodenames = list(nx.get_node_attributes(nwnet, \"name\").values())\n",
    "nodenames[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over nodes and add its node name \n",
    "#not_there = []\n",
    "\n",
    "#for n in list(nwnet.nodes()):\n",
    "    \n",
    "    #if n in list(h_e.keys()):\n",
    "        #nx.set_node_attributes(nwnet, values=h_e[n], name='name')\n",
    "    #else:\n",
    "        #not_there.append(n)\n",
    "\n",
    "#len(not_there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the not_there list to check ncbi for any updated IDs \n",
    "# (the network is 1 year old, so there may have neen changes.)\n",
    "not_there = pd.DataFrame(not_there)\n",
    "\n",
    "with open('not_there.txt', 'w') as f:\n",
    "    not_there.to_csv(f, sep='\\n',header=False, index=False)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used rentrez in R to generate the following file (see notebook) \n",
    "# to analyze the HGNC ID and the ENSEMBL gene ID for each of the not_there genes.\n",
    "\n",
    "# upload file\n",
    "with open('now_there.csv', 'r') as f:\n",
    "    now_there = pd.read_csv(f, sep=' ', header=None)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100124402</td>\n",
       "      <td>LOC100124402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100126583</td>\n",
       "      <td>LOC100126583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100127889</td>\n",
       "      <td>C10orf131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1\n",
       "0  100124402  LOC100124402\n",
       "1  100126583  LOC100126583\n",
       "2  100127889     C10orf131"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check file\n",
    "now_there.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2650"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we still have 2650 \n",
    "len(now_there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2650"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dict wit these ids\n",
    "h_en = {}\n",
    "\n",
    "# start adding to dict\n",
    "for line in range(0,len(now_there)):\n",
    "    h_en[str(now_there.iloc[line,0])] = now_there.iloc[line,1]\n",
    "        \n",
    "f.close()\n",
    "len(list(h_en.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update node attribute with node names that are now there\n",
    "nx.set_node_attributes(nwnet, values=h_en, name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dict of nodenames\n",
    "nw_nodedict = nx.get_node_attributes(nwnet, \"name\")\n",
    "# get list of node names\n",
    "nw_nodelist = list(nw_nodedict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25668, 25689)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure no duplicate node names\n",
    "# there must be some duplicates that arose after adding the second round of names  \n",
    "len(np.unique(nw_nodelist)),len(nw_nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LOC100124402'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that some of the ones that weren't there are now there \n",
    "nodenames = nx.get_node_attributes(nwnet, \"name\")\n",
    "nodenames['100124402'] # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure post_prob (edge wts) there\n",
    "# probs = list(nx.get_edge_attributes(nwnet, \"post_prob\").values())\n",
    "# probs[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write pickle \n",
    "with open('nwnet', 'wb') as f:\n",
    "    nx.write_gpickle(nwnet, f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cx to upload to ndex \n",
    "# nwnet_2upload = ndex2.create_nice_cx_from_networkx(nwnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ndex2 import niceCXNetwork as ndw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to ndex\n",
    "# nwnet_2upload.upload_to('http://test.ndexbio.org', 'ensilva', 'strgrl18')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
